{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ruled-truck",
   "metadata": {},
   "source": [
    "# Embedded ML Lab - Excercise 3 - Pruning\n",
    "\n",
    "Now we will focus on structured pruning to save computation time. We will do this in three steps.  \n",
    "* We will implement a function, similar to previous l1 pruning, to sets whole output channels to zero.  \n",
    "\n",
    "* We will delete the zeroed-out channels and densify the network again to have a reduction in computation time.\n",
    "\n",
    "* We will retrain the network to gain accuracy again.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.rand(1).to('cuda') #initialize cuda context (might take a while)\n",
    "\n",
    "from net import PrunedCifarNet\n",
    "import torch\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "testloader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10('data/', train=False, download=True, transform=tf), shuffle=False, batch_size=32)\n",
    "trainloader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10('data/', train=True, download=True, transform=tf), shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-steps",
   "metadata": {},
   "source": [
    "First, we focus on setting the output channels to zero.  \n",
    "Your Task:\n",
    "   * Implement the function `l1_structured_pruning`, that takes a `state_dict` and a `prune_ratio` as input. Calculate the l1 norm $||x||_1= \\sum_{i=1}^N |x_i|$, of each output channel, and set the output channels with the lowest norm to zero to meet the prune_ratio.\n",
    "       * Also, for each output channels that is zeroed-out, set the convolution's bias to zero\n",
    "       * You can keep `conv1` and `conv2` unpruned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde65ab8-9997-4494-a93d-65d3e95fd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_structured_pruning(state_dict: Dict, prune_ratio: float) -> Dict:\n",
    "    state_dict = copy.deepcopy(state_dict)\n",
    "    \n",
    "    #-to-be-done-by-student------\n",
    "\n",
    "    \n",
    "    #----------------------------\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25290ec",
   "metadata": {},
   "source": [
    "We now iteratively test the function for several pruning ratios. Right now, we get no gains in MACs (Multiply-accumulate operations), since the values are just set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9051c-8e37-4e70-9d0b-070f2e5067ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import copy\n",
    "\n",
    "from utils import net_acc, net_time, net_macs, plot\n",
    "\n",
    "ratios = np.linspace(0, 0.8, 15)\n",
    "\n",
    "state_dict = torch.load('state_dict__cifarnet.pt')\n",
    "accuracy_l1, idxs = [], []\n",
    "for idx, ratio in tqdm.tqdm(enumerate(ratios), total=len(ratios)):\n",
    "    state_dict = l1_structured_pruning(state_dict, ratio)\n",
    "    accuracy_l1.append(net_acc(PrunedCifarNet, state_dict, testloader, batches=32, device='cuda'))\n",
    "    idxs.append(idx)\n",
    "plot([(idxs, accuracy_l1, 'accuracy_l1')], xlabel='idxs', save_path='accuracy_l1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-object",
   "metadata": {},
   "source": [
    "Next, we implement a function that removes the zeroed-out output channels to gain actual inference speed ups.\n",
    "\n",
    "Your Tasks:\n",
    "* For each `weight` tensor of conv2d layers, slice the tensor such that only the output channels with non-zero filters remain.\n",
    "* If an output channel is removed, also remove its respective bias.\n",
    "* For each consecutive conv layer, remove the input channels that are zeroed-out output channels of the previous conv layer   \n",
    "* TIP: A tensor containing channels can be reshaped using a list of indices (e.g., `new_tensor = tensor[[1,2,3,5,6,7],:,:,:]` \n",
    "* For the last conv2d layer, you have to consider the flattened  output and slice the input of the fully connected layer. In the case of the `CifarNet` we currently use, the feature map before being flatted is $2\\times 2$ with $256$ output channels, where `torch.flatten` arranges the channels starting with index $0$.\n",
    "\n",
    "As a help, check the image: Each pruned output filter (gray/vertical) appears as a pruned input (red/horizontal) in the consecutive conv layer.  \n",
    "<img src=\"src/prune.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560ab7a-5781-4285-a2de-b324f4927d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densify_state_dict(state_dict: Dict) -> Dict:\n",
    "    state_dict = copy.deepcopy(state_dict)\n",
    "    \n",
    "    #to-be-done-by-student-------\n",
    "\n",
    "\n",
    "    #----------------------------\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3eabc",
   "metadata": {},
   "source": [
    "If you have implemented the `densify_state_dict` function correctly, the plot (orange) should behave exactly the same (orange and blue should overlap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77531fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('state_dict__cifarnet.pt')\n",
    "accuracy_dense = []\n",
    "for idx, ratio in tqdm.tqdm(enumerate(ratios), total=len(ratios)):\n",
    "    state_dict = l1_structured_pruning(state_dict, ratio)\n",
    "    sd = densify_state_dict(state_dict)\n",
    "    accuracy_dense.append(net_acc(PrunedCifarNet, sd, testloader, batches=32, device='cuda'))\n",
    "plot([(idxs, accuracy_l1, 'accuracy_l1'), (idxs, accuracy_dense, 'accuracy_dense')], xlabel='idxs', save_path='accuracy_l1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-destiny",
   "metadata": {},
   "source": [
    "Now we implement the last missing pieces to apply iterative pruning. To save time, we only apply changes to the last linear layer, all other layers are frozen.\n",
    "\n",
    "Your Tasks:\n",
    "* Implement a training function that takes the `model_class` the `state_dict`, the `trainloader`, the number of batches, and device (cpu/cuda) as input and returns a state_dict as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_class: torch.nn.Module, state_dict: Dict,\n",
    "          trainloader: torch.utils.data.DataLoader, batches: int=64, device: str='cpu'):\n",
    "\n",
    "    # Learning rate\n",
    "    lr = 0.01\n",
    "\n",
    "    torch_device = torch.device(device)\n",
    "\n",
    "    model = model_class()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(torch_device)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    # For all conv layers we disable the calculation of gradients in the backwards step\n",
    "    for key, param in model.named_parameters():\n",
    "        if any(x in key for x in ['1', '2', '3', '4', '5', '6']):\n",
    "            param.requires_grad = False\n",
    "    # The optimizer gets only the parameters that require gradient calculation\n",
    "    optimizer = torch.optim.SGD(filter(lambda x: x.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    # Loss function\n",
    "    loss_f = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    for idx, (inputs, targets) in enumerate(trainloader):\n",
    "        \n",
    "    #-to-be-done-by-student-----\n",
    "\n",
    "    #---------------------------\n",
    "    return model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-detail",
   "metadata": {},
   "source": [
    "We now iteratively prune some percent and retrain the densified state dict. We therefor use an adaptable `PrunedCifarNet` that changes the layer definition based on the parameters dimensions of the state dict.\n",
    "\n",
    "Furthermore, we plot two versions: One with fine-tuned parameters, one where no re-training is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef47a1-4367-47f7-ac77-ab1a071c6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ratios\n",
    "ratios = [0.0] + [0.025 for _ in range(25)]\n",
    "state_dict = torch.load('state_dict__cifarnet.pt')\n",
    "accuracy_from_scratch, accuracy_fine_tuned, macs = [], [], []\n",
    "for ratio in tqdm.tqdm(ratios):\n",
    "    \n",
    "    # Setting Filters to zero\n",
    "    state_dict = l1_structured_pruning(state_dict, ratio)\n",
    "    \n",
    "    # Densifying the state dict\n",
    "    state_dict = densify_state_dict(copy.deepcopy(state_dict))\n",
    "    \n",
    "    # Accuracy calculation\n",
    "    accuracy_from_scratch.append(net_acc(PrunedCifarNet, state_dict, testloader, batches=32, device='cuda'))\n",
    "\n",
    "#We now do the same with training for comparions (this might take a while)\n",
    "state_dict = torch.load('state_dict__cifarnet.pt')\n",
    "for ratio in tqdm.tqdm(ratios):\n",
    "    state_dict = l1_structured_pruning(state_dict, ratio)\n",
    "    state_dict = densify_state_dict(copy.deepcopy(state_dict))\n",
    "    \n",
    "    #We fine tune the network by training with 150 batches\n",
    "    state_dict = train(PrunedCifarNet, state_dict, trainloader, batches=32, device='cuda')\n",
    "    accuracy_fine_tuned.append(net_acc(PrunedCifarNet, state_dict, testloader, batches=32, device='cuda'))\n",
    "    macs.append(net_macs(PrunedCifarNet, state_dict))\n",
    "    \n",
    "    \n",
    "plot([(macs, accuracy_from_scratch, 'accuracy_scratch'),\n",
    "      (macs, accuracy_fine_tuned, 'accuracy_fine_tuned')],\n",
    "      xlabel='MACs [relative to max]', save_path='accuracy_macs.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
