{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914dca14-faee-449f-96a2-d218fd54455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/VOCtrainval_11-May-2012.tar\n",
      "Extracting data/VOCtrainval_11-May-2012.tar to data/\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# A subset of VOCDataLoader just for one class (person) (0)\n",
    "from utils.dataloader import VOCDataLoaderPerson\n",
    "\n",
    "loader = VOCDataLoaderPerson(train=True, batch_size=1, shuffle=True)\n",
    "loader_test = VOCDataLoaderPerson(train=False, batch_size=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953f5907-bc30-4750-896d-9c9d762a29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn):\n",
    "    with torch.no_grad():\n",
    "        # Fuse conv and bn layers\n",
    "        fusedconv = torch.nn.Conv2d(conv.in_channels,\n",
    "                                    conv.out_channels,\n",
    "                                    kernel_size=conv.kernel_size,\n",
    "                                    stride=conv.stride,\n",
    "                                    padding=conv.padding,\n",
    "                                    bias=True).to(device)\n",
    "\n",
    "        # Prepare filters\n",
    "        w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "        w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var))).to(device)\n",
    "\n",
    "        fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.size()))\n",
    "\n",
    "        # Prepare spatial bias\n",
    "        if conv.bias is None:\n",
    "            b_conv = torch.zeros(conv.weight.size(0)).to(device)\n",
    "        else:\n",
    "            b_conv = conv.bias\n",
    "\n",
    "        b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps)).to(device)\n",
    "\n",
    "        fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
    "\n",
    "        return fusedconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec867fd-3719-4333-a101-87ac89fae444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0934c061-bc9b-44dc-bc24-0ea7d6ff533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyyolov2NoBN import TinyYoloV2NoBN\n",
    "from tinyyolov2 import TinyYoloV2\n",
    "\n",
    "# Initialize the original model and load the weights\n",
    "origin_net = TinyYoloV2(num_classes=1).to(device)\n",
    "\n",
    "# load pretrained weights\n",
    "state_dict = torch.load(\"models/voc_finetuned_100_epochs_lr0001_decay0005.pt\")\n",
    "origin_net.load_state_dict(state_dict)\n",
    "\n",
    "# Create a new model without BatchNorm layers\n",
    "fused_net = TinyYoloV2NoBN(num_classes=1).to(device)\n",
    "\n",
    "# Fuse each conv and bn layer\n",
    "fused_net.conv1 = fuse_conv_and_bn(origin_net.conv1, origin_net.bn1)\n",
    "fused_net.conv2 = fuse_conv_and_bn(origin_net.conv2, origin_net.bn2)\n",
    "fused_net.conv3 = fuse_conv_and_bn(origin_net.conv3, origin_net.bn3)\n",
    "fused_net.conv4 = fuse_conv_and_bn(origin_net.conv4, origin_net.bn4)\n",
    "fused_net.conv5 = fuse_conv_and_bn(origin_net.conv5, origin_net.bn5)\n",
    "fused_net.conv6 = fuse_conv_and_bn(origin_net.conv6, origin_net.bn6)\n",
    "fused_net.conv7 = fuse_conv_and_bn(origin_net.conv7, origin_net.bn7)\n",
    "fused_net.conv8 = fuse_conv_and_bn(origin_net.conv8, origin_net.bn8)\n",
    "\n",
    "# Copy the final conv layer directly (since it doesn't have BN)\n",
    "fused_net.conv9 = origin_net.conv9\n",
    "\n",
    "fused_net.eval()\n",
    "# Save the fused model state dict\n",
    "#fused_weights_path = 'path/to/your/fused_weights.pth'\n",
    "torch.save(fused_net.state_dict(), 'models/voc_fused_100_epochs_lr0001_decay0005.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
