{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e2142c-e886-4615-8ff0-9c680c052691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import tqdm\n",
    "import copy\n",
    "from tinyyolov2NoBN import TinyYoloV2NoBN\n",
    "from pruned_tinyyolov2NoBN import PrunedTinyYoloV2NoBN \n",
    "from typing import Dict, List\n",
    "\n",
    "from utils.ap import precision_recall_levels, ap, display_roc\n",
    "from utils.yolo import nms, filter_boxes\n",
    "from utils.loss import YoloLoss\n",
    "\n",
    "from utils.dataloader import VOCDataLoaderPerson\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0349791c-be5e-4cf8-aed4-f291092d932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = VOCDataLoaderPerson(train=True, batch_size=32, shuffle=True)\n",
    "loader_test = VOCDataLoaderPerson(train=False, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d176482-6c63-4eb8-86cf-c34192e0a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_structured_pruning(state_dict: Dict, prune_ratio: float) -> Dict:\n",
    "    state_dict = copy.deepcopy(state_dict)\n",
    "    \n",
    "    for name, param in state_dict.items():\n",
    "        # Only prune conv layers, excluding conv1 and conv9\n",
    "        if 'conv' in name and 'weight' in name and 'conv1' not in name and 'conv9' not in name:\n",
    "            weight = state_dict[name]\n",
    "            out_channels = weight.shape[0]\n",
    "            num_channels_to_prune = int(out_channels*prune_ratio)\n",
    "            if num_channels_to_prune < 1:\n",
    "                continue\n",
    "            l1 = torch.sum(torch.abs(weight), (1, 2, 3))\n",
    "            zero_out_channels = torch.argsort(l1)\n",
    "            \n",
    "            for i in range(num_channels_to_prune):\n",
    "                weight[zero_out_channels[i], :, :, :] = 0\n",
    "            \n",
    "            state_dict[name] = weight\n",
    "            \n",
    "            bias_key = name.replace('weight', 'bias')\n",
    "            bias = state_dict[bias_key]\n",
    "            for i in range(num_channels_to_prune):\n",
    "                bias[zero_out_channels[i]] = 0\n",
    "            \n",
    "            state_dict[bias_key] = bias\n",
    "            \n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd60e42-c0e6-41cb-befd-2d805aa373f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densify_state_dict(state_dict: Dict) -> Dict:\n",
    "    state_dict = copy.deepcopy(state_dict)\n",
    "    \n",
    "    mask = None\n",
    "    \n",
    "    for layer in range(1, 10):\n",
    "        l = \"conv\" + str(layer) + \".\"\n",
    "        w = l + \"weight\"\n",
    "        b = l + \"bias\"\n",
    "        \n",
    "        weights = state_dict[w]\n",
    "        biases = state_dict[b]\n",
    "        if mask is not None:\n",
    "            weights = weights[:,mask,:,:]\n",
    "            \n",
    "        mask = torch.nonzero(weights.sum(dim=[1,2,3]), as_tuple=True)[0].tolist()\n",
    "        \n",
    "        weights = weights[mask,:,:,:]\n",
    "        biases = biases[mask]\n",
    "        \n",
    "        state_dict[w] = weights\n",
    "        state_dict[b] = biases\n",
    "    \n",
    "    #weights = state_dict[\"fc.weight\"]\n",
    "    \n",
    "    #fcmask = []\n",
    "    #for channel in mask:\n",
    "    #    for i in range(4):\n",
    "    #        fcmask.append(channel * 4 + i)\n",
    "    \n",
    "    #state_dict[\"fc.weight\"] = weights[:,fcmask]\n",
    "    \n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcf872e-235c-4dfd-8d5d-da9c3866ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PrunedTinyYoloV2NoBN(num_classes=1)\n",
    "state_dict = torch.load(\"fusedyolov2_0717.pt\", map_location=device)\n",
    "net.load_state_dict(state_dict, strict=False)\n",
    "net.to(device)\n",
    "\n",
    "frozedLayers = []\n",
    "lr = 0.001\n",
    "weight_decay = 0.005\n",
    "\n",
    "criterion = YoloLoss(anchors=net.anchors)\n",
    "\n",
    "\n",
    "for key, param in net.named_parameters():\n",
    "    if any(x in key for x in frozedLayers):\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, net.parameters()), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e388b-cf38-4baa-9c17-52bb78b5e821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Pruning iteration 1/20-----\n",
      "Pruning done.\n",
      "Training started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "NUM_TEST_SAMPLES = 30\n",
    "NUM_EPOCHS = 20\n",
    "test_AP = []\n",
    "num_iterations = 20\n",
    "ratio = 0.1\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(f\"-----Pruning iteration {iteration+1}/{num_iterations}-----\")\n",
    "    state_dict = l1_structured_pruning(net.cpu().state_dict(), ratio)\n",
    "    state_dict = densify_state_dict(state_dict)\n",
    "    net.load_state_dict(state_dict)\n",
    "    print(f\"Pruning done.\")\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        if epoch >= 0:\n",
    "            net.train()\n",
    "            net.to(device)\n",
    "            print(\"Training started.\")\n",
    "            for idx, (input, target) in tqdm.tqdm(enumerate(loader), total=len(loader)):\n",
    "                input, target = input.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                #Yolo head is implemented in the loss for training, therefore yolo=False\n",
    "                output = net(input, yolo=False)\n",
    "                loss, _ = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "        test_precision = []\n",
    "        test_recall = []\n",
    "        net.eval()\n",
    "        print(\"Validation started.\")\n",
    "        with torch.no_grad():\n",
    "            for idx, (input, target) in tqdm.tqdm(enumerate(loader_test), total=NUM_TEST_SAMPLES):\n",
    "                input, target = input.to(device), target.to(device)\n",
    "                output = net(input, yolo=True)\n",
    "        \n",
    "                #The right threshold values can be adjusted for the target application\n",
    "                output = filter_boxes(output, 0.0)\n",
    "                output = nms(output, 0.5)\n",
    "        \n",
    "                precision, recall = precision_recall_levels(target[0], output[0])\n",
    "                test_precision.append(precision)\n",
    "                test_recall.append(recall)\n",
    "                if idx == NUM_TEST_SAMPLES:\n",
    "                    break\n",
    "                \n",
    "        #Calculation of average precision with collected samples\n",
    "        test_AP.append(ap(test_precision, test_recall))\n",
    "        print('average precision', test_AP)\n",
    "\n",
    "        #plot ROC\n",
    "        display_roc(test_precision, test_recall)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550cfda-b47d-4ada-b1ca-65184136eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict, 'pruned_tinyyolov2NoBN.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
