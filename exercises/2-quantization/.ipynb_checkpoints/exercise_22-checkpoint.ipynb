{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chinese-specific",
   "metadata": {},
   "source": [
    "# Embedded ML Lab - Excercise 2 - Quantization (additional experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-ministry",
   "metadata": {},
   "source": [
    "Until now, we always used a symmetric min/max scale for quantization of the activations, hence a centered zero point.\n",
    "\n",
    "We will now do two things to squeeze a little bit more accuracy out of the quantization  \n",
    "* Firstly, we will loosen our assumption of a symmetric range/zero_point\n",
    "* Secondly, we will consider \"cutting away\" parts that are not important for the classification choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import CifarNet\n",
    "import torch\n",
    "\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "testloader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10('data/', train=False, download=True, transform=tf), shuffle=False, batch_size=32)\n",
    "\n",
    "import time\n",
    "import nbimporter \n",
    "\n",
    "from exercise_21 import net_time\n",
    "from exercise_21 import net_acc\n",
    "from exercise_21 import fuse_conv_bn_weights\n",
    "from exercise_21 import QCifarNet, QConv2dReLU, QLinear\n",
    "from exercise_21 import tensor_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-congo",
   "metadata": {},
   "source": [
    "We introduce two changed Modules (`QConv2dreluNSym`, `QLinerNSym`) that besides a scale (like in the last exercise) also have an adjustable zero_point that can be also set through the state_dict.\n",
    "\n",
    "We use these two Modules in a new Classifier called `QCifarNetSym`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.quantized.modules.utils import _pair_from_first\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Both classes now also have a state-dict entry for the zero_point\n",
    "class QConv2dReLUNSym(QConv2dReLU):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(QConv2dReLUNSym, self).__init__(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.register_buffer('zero_point', torch.tensor(64))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.ops.quantized.conv2d_relu(x, self._prepack, self.scale, self.zero_point)\n",
    "\n",
    "    \n",
    "class QLinearNSym(QLinear):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(QLinearNSym, self).__init__(in_features, out_features)\n",
    "        self.register_buffer('zero_point', torch.tensor(64))\n",
    "   \n",
    "    def forward(self, x):\n",
    "        return torch.ops.quantized.linear(x, self._prepack, self.scale, self.zero_point)\n",
    "    \n",
    "    \n",
    "class QCifarNetNSym(QCifarNet):\n",
    "    def __init__(self):\n",
    "        super(QCifarNet, self).__init__()\n",
    "        \n",
    "        self.register_buffer(\"scale\", torch.tensor(0.1))\n",
    "\n",
    "        self.conv1 = QConv2dReLUNSym(3, 16, 3, 1, padding=1)\n",
    "        self.conv2 = QConv2dReLUNSym(16,16, 3, 1, padding=1)\n",
    "\n",
    "        self.conv3 = QConv2dReLUNSym(16, 32, 3, 1, padding=1)\n",
    "        self.conv4 = QConv2dReLUNSym(32, 32, 3, 1, padding=1)\n",
    "\n",
    "        self.conv5 = QConv2dReLUNSym(32, 64, 3, 1, padding=1)\n",
    "        self.conv6 = QConv2dReLUNSym(64, 64, 3, 1, padding=1)\n",
    "\n",
    "        self.fc = QLinearNSym(1024, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-marker",
   "metadata": {},
   "source": [
    "Your Task:\n",
    "   * Copy your class description of `CifarNetCalibration` from the last lab into the next block.\n",
    "   * Besides the calibration, add execute the function `plot_density` after each operator.\n",
    "   * Run the calibration batch again (code provided) and inspect the figures. What observation can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_density(x):\n",
    "    # input tensor x\n",
    "    x = x.detach()\n",
    "    plt.hist(x.flatten().numpy(), range=(float(x.min()),float(x.max())), density=True, bins=50)\n",
    "    plt.title('input probability density function')\n",
    "    plt.ylabel('likelihood')\n",
    "    plt.xlabel('values')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "#We run the calibration using a batch from the testdata\n",
    "net_calib = CifarNetCalibration()\n",
    "net_calib.load_state_dict(torch.load('state_dict.pt'))\n",
    "_, (data, _) = next(enumerate(testloader))\n",
    "net_calib(data)\n",
    "calibration_dict = net_calib.calibration_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-berlin",
   "metadata": {},
   "source": [
    "Your Task: \n",
    "* Copy Your code that sets the quantized state dict after calibration from the last lab. The state dict has now new entries `zero_point` for the fused conv and the fc layer.\n",
    "* Explore what happens if we change the scale of the conv layer in a way that better suits the plots. Use the provided code to determine the accuracy for each step.\n",
    "* After that, adjust the scale of the conv layers according to the figures\n",
    "\n",
    "Your Task:\n",
    "* After that, play around with scale and zero_point of the fully connected layer. What conclusion can we draw?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints keys from quantized net\n",
    "qnet = QCifarNetNSym()\n",
    "qsd = qnet.state_dict()\n",
    "for key in qsd: print(key, qsd[key].dtype)\n",
    "\n",
    "sd = torch.load('state_dict.pt')\n",
    "\n",
    "###--- COPY YOUR IMPLEMENTATION HERE ---\n",
    "\n",
    "\n",
    "### ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We run the accuracy test again to see how much accuracy we loose through quantization\n",
    "print(f\"Accuracy quantized: {net_acc(QCifarNetNSym, qsd, testloader):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-placement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
